{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "import io\n",
    "\n",
    "# Configurações do Minio\n",
    "minio_host = 'minio.ifpbapps.online'\n",
    "minio_access_key = \"VQdTNNVXZZLXNMRnV4RDFoQ2MtZGFSRjN3Q0Z2Z\"\n",
    "minio_secret_key = \"pMnQ4ZkktaU9UdlRYX1c!3S1lHMkVpajU5LTRLTHl1NwbmRDVmdiWW9RaGJvZmFWSkF5YmZ\"\n",
    "minio_bucket = 'raios'\n",
    "\n",
    "# Conectar ao Minio\n",
    "minio_client = Minio(minio_host, access_key=minio_access_key, secret_key=minio_secret_key, secure=True)\n",
    "\n",
    "# Função para baixar arquivo do Minio e carregar como DataFrame\n",
    "def download_and_read_csv(minio_client, bucket, file_path):\n",
    "    try:\n",
    "        # Baixar o arquivo do Minio\n",
    "        data = minio_client.get_object(bucket, file_path)\n",
    "        \n",
    "        # Ler o CSV\n",
    "        df = pd.read_csv(data)\n",
    "        \n",
    "        return df\n",
    "    except S3Error as err:\n",
    "        print(err)\n",
    "        return None\n",
    "\n",
    "# Lista de arquivos no Minio\n",
    "files = [\n",
    "    'Consolidado Raios 2023_EPB.csv',\n",
    "    'Consolidado Raios 2023_ERO.csv',\n",
    "    'Consolidado Raios 2023_EMT.csv',\n",
    "    'Consolidado Raios 2023_EMS.csv',\n",
    "    'Consolidado Raios 2023_EMR.csv',\n",
    "    'Consolidado Raios 2023_EAC.csv',\n",
    "    'Consolidado Raios 2023_ETO.csv',\n",
    "    'Consolidado Raios 2023_ESS.csv',\n",
    "    'Consolidado Raios 2023_ESE.csv'\n",
    "]\n",
    "\n",
    "# Lista para armazenar DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Iterar sobre os arquivos e baixar do Minio\n",
    "for file in files:\n",
    "    df = download_and_read_csv(minio_client, minio_bucket, file)\n",
    "    if df is not None:\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenar os DataFrames\n",
    "Descargas_Energisa = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "Dados carregados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "minio_secure = True\n",
    "\n",
    "# Nome do bucket e pasta no Minio\n",
    "minio_bucket = 'raios'\n",
    "minio_folder = ''\n",
    "\n",
    "# Inicializa o cliente Minio\n",
    "minio_client = Minio(minio_host, access_key=minio_access_key, secret_key=minio_secret_key, secure=True)\n",
    "\n",
    "# Carrega os códigos do IBGE\n",
    "cod_ibge_data = minio_client.get_object(minio_bucket, f'{minio_folder}dados-ibge.xls')\n",
    "cod_ibge_buffer = io.BytesIO(cod_ibge_data.read())\n",
    "cod_ibge = pd.read_excel(cod_ibge_buffer, header=6)\n",
    "\n",
    "colunas_ocorrencias = ['DscOcorrenciaAberta', 'CodIBGE']\n",
    "\n",
    "# Carrega as ocorrências da ANEEL\n",
    "ocorrencias_data = minio_client.get_object(minio_bucket, f'{minio_folder}ocorrencias-emergenciais-rede-distribuicao-2023.csv')\n",
    "ocorrencias_buffer = io.BytesIO(ocorrencias_data.read())\n",
    "ocorrencias = pd.read_csv(ocorrencias_buffer, delimiter=';', encoding='latin-1', low_memory=False, usecols=colunas_ocorrencias)\n",
    "\n",
    "# Se chegou até aqui, os dados foram carregados com sucesso\n",
    "print(\"Dados carregados com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deixando um único dataframe pra todas as descargas do grupo Energisa\n",
    "Lista_Descargas = [Descargas_EPB, Descargas_ERO, Descargas_EMT, Descargas_EMS, Descargas_EMR, Descargas_EAC, Descargas_ETO, Descargas_ESS, Descargas_ESE]\n",
    "\n",
    "# Mantendo apenas as colunas da base que possuem dados de raios no sentido Nuvem-Solo\n",
    "Descargas_Energisa = Descargas_Energisa.iloc[:, [0, 1, 4, 7, 10, 13, 16, 19, 22, 25, 28, 31, 34]]\n",
    "\n",
    "#  Excluir a primeira linha, pois a tabela só começa na terceira linha\n",
    "Descargas_Energisa = Descargas_Energisa.drop(0)\n",
    "\n",
    "# Renomear todas as colunas para que fique de acordo com o número de raios nos meses correspondentes \n",
    "novos_nomes_colunas = ['Localidade', 'Janeiro', 'Fevereiro', 'Março', 'Abril', 'Maio', 'Junho', 'Julho', 'Agosto', 'Setembro', 'Outubro', 'Novembro', 'Dezembro']\n",
    "Descargas_Energisa.columns = novos_nomes_colunas\n",
    "\n",
    "# Filtrando apenas ocorrências que sejam advindas de descargas atmosféricas\n",
    "Ocorrencias = ocorrencias[ocorrencias['DscOcorrenciaAberta'] == \"INTERNA;NAO PROGRAMADA;MEIO AMBIENTE;DESCARGA ATMOSFERICA\"]\n",
    "\n",
    "# Agora, adicionando a coluna \"Cod_IBGE\" para cada DataFrame na Lista_Descargas\n",
    "for base in Lista_Descargas:\n",
    "    # Obtém o estado da base atual\n",
    "    estado = base.iloc[0]['Localidade']\n",
    "    \n",
    "    # Filtra o DataFrame Cod_IBGE para o estado correspondente\n",
    "    cod_ibge_estado = Cod_IBGE[Cod_IBGE['Nome_UF'] == estado]\n",
    "    \n",
    "    # Mescla os DataFrames com base no município\n",
    "    base = pd.merge(base, cod_ibge_estado[['Nome_Município', 'Cod_IBGE']], how='left', left_on='Localidade', right_on='Município')\n",
    "    \n",
    "    # Remove a coluna redundante\n",
    "    base = base.drop(columns='Município')\n",
    "    \n",
    "    # Renomeia a coluna Cod_IBGE\n",
    "    base = base.rename(columns={'Cod_IBGE': 'Cod_IBGE'})\n",
    "\n",
    "# Agora, cada DataFrame na Lista_Descargas terá uma nova coluna 'Cod_IBGE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.7\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425350 sha256=0511c443cf6b7528c6a690dbae90831cce8efc4152fad330d4c1b28fa40cf032\n",
      "  Stored in directory: /home/ruanv/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
